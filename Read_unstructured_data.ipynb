{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef57eb5-2295-44fb-81d9-4351769e8f4e",
   "metadata": {},
   "source": [
    "This notebook is to demostrate how you can read and analyze any document - PDF, HTML, PPT, Image etc. It uses python open source package 'Unstructured', followed by Open AI LLM to perform end to end retrieval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec2430d-cac6-406e-a007-123dc97df0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b2b85e-9cd5-44ff-8d56-05fed300e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install unstructured-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "740e91e8-8333-4a33-8bca-c15f3ceee2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "591f213d-f54b-4c91-ae73-bcd2c7a4359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "import json\n",
    "import os\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "from unstructured.staging.base import dict_to_elements, elements_to_json\n",
    "\n",
    "from unstructured_client import UnstructuredClient\n",
    "from unstructured_client.models import shared\n",
    "from unstructured_client.models.errors import SDKError\n",
    "\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.pptx import partition_pptx\n",
    "from unstructured.staging.base import dict_to_elements\n",
    "\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b97be736-2166-400c-9d17-6dcb4034c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import Utils\n",
    "import os\n",
    "utils = Utils()\n",
    "\n",
    "DLAI_API_KEY = utils.get_dlai_api_key()\n",
    "DLAI_API_URL = utils.get_dlai_url()\n",
    "#os.environ['DLAI_API_KEY'] = 'EhA5zYMRXZlZeR8V46ZEsUKziVRxag'\n",
    "#os.environ['DLAI_API_URL'] = 'https://api.unstructured.io/general/v0/general'\n",
    "\n",
    "s = UnstructuredClient(\n",
    "    api_key_auth=DLAI_API_KEY,\n",
    "    server_url=DLAI_API_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d1f316-a4f0-4178-9d1b-96dcff5c0ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vnirwan\\\\Desktop\\\\Vaishu\\\\AI Course\\\\GDrive'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01e76f-3773-4611-9ad8-5f990ab23eef",
   "metadata": {},
   "source": [
    "## Example Document: Medium Blog HTML Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0265c17e-d9db-4877-a804-74d94596a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Forgit/Ethical_Challenges_Medium.html\"\n",
    "elements_html = partition_html(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0c8db-c6a1-48d7-a905-6212c06ce143",
   "metadata": {},
   "source": [
    "We can also get these elements in a json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68f55cc9-0d04-4260-a617-9f3ab0c6951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"Title\",\n",
      "    \"element_id\": \"8d23208bb22c5e662570b8a8a84db477\",\n",
      "    \"text\": \"1. Privacy at Risk: The Dangers of Data Overreach \\ud83d\\udd0d\",\n",
      "    \"metadata\": {\n",
      "      \"category_depth\": 1,\n",
      "      \"last_modified\": \"2024-09-11T23:34:23\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"8c55b5e80e73435e369db4ba08b0f337\",\n",
      "      \"file_directory\": \"Forgit\",\n",
      "      \"filename\": \"Ethical_Challenges_Medium.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"0318f52ce3254b0c09d157517a4d133a\",\n",
      "    \"text\": \"\\ud83d\\udccdIssue 1: Data Collection Overload AI thrives on data, and often, this data is personal. AI systems collect vast amounts of personal information from everyday interactions \\u2014 raising eyebrows about how this information is stored, used, and protected.\",\n",
      "    \"metadata\": {\n",
      "      \"emphasized_text_contents\": [\n",
      "        \"Issue 1: Data Collection Overload\"\n",
      "      ],\n",
      "      \"emphasized_text_tags\": [\n",
      "        \"b\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-11T23:34:23\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"8d23208bb22c5e662570b8a8a84db477\",\n",
      "      \"file_directory\": \"Forgit\",\n",
      "      \"filename\": \"Ethical_Challenges_Medium.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"57b8052ce3d33b45c22430cb867dd505\",\n",
      "    \"text\": \"\\ud83d\\uded1 Examples: Smart home assistants like Alexa or Google Home constantly gather data on users. While this can improve user experience, the lack of transparency on how this data is managed has triggered numerous privacy concerns.\",\n",
      "    \"metadata\": {\n",
      "      \"emphasized_text_contents\": [\n",
      "        \"Examples\"\n",
      "      ],\n",
      "      \"emphasized_text_tags\": [\n",
      "        \"b\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-11T23:34:23\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"8d23208bb22c5e662570b8a8a84db477\",\n",
      "      \"file_directory\": \"Forgit\",\n",
      "      \"filename\": \"Ethical_Challenges_Medium.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"NarrativeText\",\n",
      "    \"element_id\": \"b2d9db6397b94a63dfeecc64cb93c6c2\",\n",
      "    \"text\": \"\\ud83d\\udccdIssue 2: Constant Surveillance Public spaces are increasingly monitored with AI-powered surveillance tools, like traffic cameras with facial recognition, raising ethical dilemmas. Although this can enhance security, it\\u2019s also a breach of privacy for those unaware of being recorded.\",\n",
      "    \"metadata\": {\n",
      "      \"emphasized_text_contents\": [\n",
      "        \"Issue 2: Constant Surveillance\"\n",
      "      ],\n",
      "      \"emphasized_text_tags\": [\n",
      "        \"b\"\n",
      "      ],\n",
      "      \"last_modified\": \"2024-09-11T23:34:23\",\n",
      "      \"languages\": [\n",
      "        \"eng\"\n",
      "      ],\n",
      "      \"parent_id\": \"8d23208bb22c5e662570b8a8a84db477\",\n",
      "      \"file_directory\": \"Forgit\",\n",
      "      \"filename\": \"Ethical_Challenges_Medium.html\",\n",
      "      \"filetype\": \"text/html\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in elements_html]\n",
    "example_output = json.dumps(element_dict[11:15], indent=2)\n",
    "print(example_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9543cf79-a28f-4adc-8e26-b42d019dfa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Forgit/Presentation.pptx\"\n",
    "elements_ppt = partition_pptx(filename=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37b2175b-d155-4275-867c-c91d425f912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import chromadb\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b273ddcd-7bd8-41e2-8449-b4d4070bfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = chunk_by_title(elements_html+elements_ppt)\n",
    "elements = chunk_by_title(elements_ppt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa936eea-f488-49bb-b3dc-00b665816ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for element in elements:\n",
    "    metadata = element.metadata.to_dict()\n",
    "    del metadata[\"languages\"]\n",
    "    metadata[\"source\"] = metadata[\"filename\"]\n",
    "    documents.append(Document(page_content=element.text, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a7031ec-7e8d-4728-8790-47ea025513d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"yourkey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b10979f4-8333-468d-95af-caaf8aa06b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0270823-29f2-4c17-a4b3-eb4dde09dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d63264b7-93f6-4ad7-a9b6-ff0c9efa0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8877ee2-a3b2-4f5a-bf55-d87009e0f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions related to the results and conclusions we got from these analyses about SIMS. Try to understand the context of a conclusion while using the information from these files. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about SIMS, politely inform them that you are tuned to only answer questions about Donut.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab4de674-b7c2-4db2-aefb-9e515860d672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnirwan\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\vnirwan\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use create_history_aware_retriever together with create_retrieval_chain (see example in docstring) instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
    "question_generator_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "qa_chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator_chain,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "323b1efd-053d-4680-93b8-414fdc55835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Some key ethical implications of AI's rise include potential bias and discrimination, lack of transparency and accountability, job displacement, and privacy and security concerns.\\nSOURCES: Presentation.pptx\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke({\n",
    "    \"question\": \" What are key ethical implications of AIâ€™s rise?\",\n",
    "    \"chat_history\": []\n",
    "})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa5337a4-faab-414c-b034-169fd4bd2fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Artificial Intelligence works by using machine learning to perform calculations and make decisions. It has the potential to be biased and has been used in the field of cybersecurity to detect and prevent attacks. \\nSOURCES: Presentation.pptx'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke({\n",
    "    \"question\": \"How does Artifical Intelligence work\",\n",
    "    \"chat_history\": []\n",
    "})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee2322-6829-4d3a-9666-6b6440c7d074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
