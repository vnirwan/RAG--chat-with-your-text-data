{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c097108-0444-4d25-ba82-b9c4937e9af5",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of the RAG technique, reading data from a text file to answer users' questions based on the provided data.Used OpenAI embeddings to convert text to embeddings for vectorDB.\n",
    "\n",
    "Two methods are explored in this notebook:\n",
    "\n",
    "1) Using the similarity search function of VectorDB.\n",
    "2) Using OpenAI's LLM to search for relevant information.\n",
    "The text file used contains data from news articles. For guidance on scraping a news website to obtain news article data, please refer to the news_extraction file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141f58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b7dff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "#pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1958629c-9fe3-45ba-be47-ee095fe20190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = r'your_dir'\n",
    "\n",
    "# Change the current working directory to the specified directory\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0c7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openaikey\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8111fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "#loader = TextLoader(\"C:/Users/vnirwan/Desktop/Vaishu/AI Course/article_text_files/Welcome to Playtesting in Guildford!.txt\",encoding='utf-8')\n",
    "loader = TextLoader(\"your_dir/merged_content.txt\",encoding='utf-8')\n",
    "loader.load()\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "274e5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "#Split the text so that there is some overlap to preserve connected information\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8a20186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 295, which is longer than the specified 200\n",
      "Created a chunk of size 306, which is longer than the specified 200\n",
      "Created a chunk of size 387, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3371b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb909b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnirwan\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5caa7",
   "metadata": {},
   "source": [
    "Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2f03e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'your_dir/docs/chroma_news/'\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits, #splits that we created of our documents\n",
    "    embedding=embedding, #the openai embedd model\n",
    "    persist_directory=persist_directory #this is a variable specific to chroma, that allows us to save \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1c90367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5fb67-1807-4616-a66d-64833fe47c1a",
   "metadata": {},
   "source": [
    "Using similarity_search function to find information in vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8dd7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"your_question\" #Lets ask a questions\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "#print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bafb14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to see metadata\n",
    "#for doc in docs:\n",
    "#    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "57ddd8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(docs[1].page_content) #See content of a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c56602c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e845d",
   "metadata": {},
   "source": [
    "Using openai model to add a conversational feature to our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ad33167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8058a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding) #loading our vector db that we created in previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eba1b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eac977dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnirwan\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864a4bb",
   "metadata": {},
   "source": [
    "Retriaval QnA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "408fb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51d547b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnirwan\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "636e225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dc7f4",
   "metadata": {},
   "source": [
    "Can also provide default prompts to your llm, so that users don't have to write it eveytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "53ae490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe9d0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True, #This will let us easily inspect the documents that we retrieve\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\" #this type of chain iterates over results to get you the best result possible\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18e59dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is there any infrmation on Welcome to Playtesting in Guildford!?\"\n",
    "result = qa_chain({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b524c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_refine = qa_chain_mr({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb97aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_refine[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17a397-91fe-4fad-a8b2-5a9a0cc27d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
